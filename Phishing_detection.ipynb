{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_url</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>ip</th>\n",
       "      <th>http_in_path</th>\n",
       "      <th>https_token</th>\n",
       "      <th>ratio_digits_url</th>\n",
       "      <th>ratio_digits_host</th>\n",
       "      <th>punycode</th>\n",
       "      <th>port</th>\n",
       "      <th>tld_in_path</th>\n",
       "      <th>...</th>\n",
       "      <th>empty_title</th>\n",
       "      <th>domain_in_title</th>\n",
       "      <th>domain_with_copyright</th>\n",
       "      <th>whois_registered_domain</th>\n",
       "      <th>domain_registration_length</th>\n",
       "      <th>domain_age</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>dns_record</th>\n",
       "      <th>google_index</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>5767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4004</td>\n",
       "      <td>5828815</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>-1</td>\n",
       "      <td>107721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>8175</td>\n",
       "      <td>8725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11425</th>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>448</td>\n",
       "      <td>5396</td>\n",
       "      <td>3980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11426</th>\n",
       "      <td>84</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>6728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11427</th>\n",
       "      <td>105</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2809</td>\n",
       "      <td>8515</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11428</th>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>2836</td>\n",
       "      <td>2455493</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11429</th>\n",
       "      <td>477</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085954</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11430 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       length_url  length_hostname  ip  http_in_path  https_token  \\\n",
       "0              37               19   0             0            1   \n",
       "1              77               23   1             0            1   \n",
       "2             126               50   1             0            0   \n",
       "3              18               11   0             0            1   \n",
       "4              55               15   0             0            1   \n",
       "...           ...              ...  ..           ...          ...   \n",
       "11425          45               17   0             0            1   \n",
       "11426          84               18   0             0            1   \n",
       "11427         105               16   1             0            0   \n",
       "11428          38               30   0             0            1   \n",
       "11429         477               14   1             4            1   \n",
       "\n",
       "       ratio_digits_url  ratio_digits_host  punycode  port  tld_in_path  ...  \\\n",
       "0              0.000000           0.000000         0     0            0  ...   \n",
       "1              0.220779           0.000000         0     0            0  ...   \n",
       "2              0.150794           0.000000         0     0            0  ...   \n",
       "3              0.000000           0.000000         0     0            0  ...   \n",
       "4              0.000000           0.000000         0     0            0  ...   \n",
       "...                 ...                ...       ...   ...          ...  ...   \n",
       "11425          0.000000           0.000000         0     0            0  ...   \n",
       "11426          0.023810           0.000000         0     0            1  ...   \n",
       "11427          0.142857           0.000000         0     0            0  ...   \n",
       "11428          0.000000           0.000000         0     0            0  ...   \n",
       "11429          0.085954           0.785714         0     0            1  ...   \n",
       "\n",
       "       empty_title  domain_in_title  domain_with_copyright  \\\n",
       "0                0                0                      1   \n",
       "1                0                1                      0   \n",
       "2                0                1                      0   \n",
       "3                0                1                      0   \n",
       "4                0                0                      1   \n",
       "...            ...              ...                    ...   \n",
       "11425            0                0                      0   \n",
       "11426            0                1                      0   \n",
       "11427            0                0                      0   \n",
       "11428            0                1                      0   \n",
       "11429            0                1                      1   \n",
       "\n",
       "       whois_registered_domain  domain_registration_length  domain_age  \\\n",
       "0                            0                          45          -1   \n",
       "1                            0                          77        5767   \n",
       "2                            0                          14        4004   \n",
       "3                            0                          62          -1   \n",
       "4                            0                         224        8175   \n",
       "...                        ...                         ...         ...   \n",
       "11425                        0                         448        5396   \n",
       "11426                        0                         211        6728   \n",
       "11427                        0                        2809        8515   \n",
       "11428                        0                          85        2836   \n",
       "11429                        1                           0          -1   \n",
       "\n",
       "       web_traffic  dns_record  google_index  status  \n",
       "0                0           1             1       0  \n",
       "1                0           0             1       1  \n",
       "2          5828815           0             1       1  \n",
       "3           107721           0             0       0  \n",
       "4             8725           0             0       0  \n",
       "...            ...         ...           ...     ...  \n",
       "11425         3980           0             0       0  \n",
       "11426            0           0             1       1  \n",
       "11427            8           0             1       0  \n",
       "11428      2455493           0             0       0  \n",
       "11429            0           1             1       1  \n",
       "\n",
       "[11430 rows x 58 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"updated_dataset.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11430, 57)\n",
      "(11430,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(\"status\", axis=1)\n",
    "Y = data[\"status\"]\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_, Y_train, Y_ = train_test_split(X, Y, test_size=0.30, random_state=42)\n",
    "X_cv, X_test, Y_cv, Y_test = train_test_split(X_, Y_, test_size=0.50, random_state=42)\n",
    "del X_,Y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8001, 57)\n",
      "(1714, 57)\n",
      "(1715, 57)\n",
      "(8001,)\n",
      "(1714,)\n",
      "(1715,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_cv.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_cv.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''dtc = DecisionTreeClassifier()\n",
    "rfc = RandomForestClassifier()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''dtc_params = [\n",
    "    {\n",
    "        \"max_depth\" : [2, 4, 5, 6, 8, 10, 11, 12, 14, 16, 18, 20, 21, 25, None],\n",
    "        \"min_samples_split\" : [2, 5, 10, 15, 20, 25, 27, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "        \"criterion\" : [\"log_loss\", \"gini\", \"entropy\"],\n",
    "    }\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''rfc_params = [\n",
    "    {\n",
    "        \"n_estimators\" : [50, 100, 150, 175, 200],\n",
    "        \"max_depth\" : [4, 6, 8, 10, 11, 12, 14, 16],\n",
    "        \"min_samples_split\" : list(range(2, 12, 2))\n",
    "    }\n",
    "] '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid=[{&#x27;criterion&#x27;: [&#x27;log_loss&#x27;, &#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                          &#x27;max_depth&#x27;: [2, 4, 5, 6, 8, 10, 11, 12, 14, 16, 18,\n",
       "                                        20, 21, 25, None],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 5, 10, 15, 20, 25, 27, 30,\n",
       "                                                40, 50, 60, 70, 80, 90, 100]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid=[{&#x27;criterion&#x27;: [&#x27;log_loss&#x27;, &#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                          &#x27;max_depth&#x27;: [2, 4, 5, 6, 8, 10, 11, 12, 14, 16, 18,\n",
       "                                        20, 21, 25, None],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 5, 10, 15, 20, 25, 27, 30,\n",
       "                                                40, 50, 60, 70, 80, 90, 100]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid=[{'criterion': ['log_loss', 'gini', 'entropy'],\n",
       "                          'max_depth': [2, 4, 5, 6, 8, 10, 11, 12, 14, 16, 18,\n",
       "                                        20, 21, 25, None],\n",
       "                          'min_samples_split': [2, 5, 10, 15, 20, 25, 27, 30,\n",
       "                                                40, 50, 60, 70, 80, 90, 100]}])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gs_cv_dtc = GridSearchCV(dtc, dtc_params, cv=4, n_jobs=-1)\n",
    "#gs_cv_dtc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 25}\n"
     ]
    }
   ],
   "source": [
    "#print(gs_cv_dtc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [4, 6, 8, 10, 11, 12, 14, 16],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 4, 6, 8, 10],\n",
       "                          &#x27;n_estimators&#x27;: [50, 100, 150, 175, 200]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [4, 6, 8, 10, 11, 12, 14, 16],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 4, 6, 8, 10],\n",
       "                          &#x27;n_estimators&#x27;: [50, 100, 150, 175, 200]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid=[{'max_depth': [4, 6, 8, 10, 11, 12, 14, 16],\n",
       "                          'min_samples_split': [2, 4, 6, 8, 10],\n",
       "                          'n_estimators': [50, 100, 150, 175, 200]}])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gs_cv_rfc = GridSearchCV(rfc, rfc_params, cv=4, n_jobs=-1)\n",
    "#gs_cv_rfc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 16, 'min_samples_split': 4, 'n_estimators': 175}\n"
     ]
    }
   ],
   "source": [
    "#print(gs_cv_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=12, max_features=&#x27;auto&#x27;, min_samples_split=25,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=12, max_features=&#x27;auto&#x27;, min_samples_split=25,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=12, max_features='auto', min_samples_split=25,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTC_model = DecisionTreeClassifier(max_depth=12, min_samples_split=25, criterion=\"gini\", max_features=\"auto\", random_state=42)\n",
    "DTC_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score on DTC model is 0.9388826396700413\n",
      "CrossValidation Score on DTC model is 0.9101516919486581\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Score on DTC model is {DTC_model.score(X_train, Y_train)}\")\n",
    "print(f\"CrossValidation Score on DTC model is {DTC_model.score(X_cv, Y_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=16, min_samples_split=40,\n",
       "                       n_estimators=150, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=16, min_samples_split=40,\n",
       "                       n_estimators=150, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=16, min_samples_split=40,\n",
       "                       n_estimators=150, random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_model = RandomForestClassifier(n_estimators=150, max_depth=16, min_samples_split=40, criterion=\"entropy\", max_features=\"sqrt\", random_state=42)\n",
    "RFC_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score on RFC model is 0.9618797650293713\n",
      "CrossValidation Score on RFC model is 0.9474912485414235\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Score on RFC model is {RFC_model.score(X_train, Y_train)}\")\n",
    "print(f\"CrossValidation Score on RFC model is {RFC_model.score(X_cv, Y_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/450\n",
      "251/251 [==============================] - 1s 1ms/step - loss: 59482.9922 - accuracy: 0.3650\n",
      "Epoch 2/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 56255.5039 - accuracy: 0.3685\n",
      "Epoch 3/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 53044.8477 - accuracy: 0.3715\n",
      "Epoch 4/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 49868.8359 - accuracy: 0.3747\n",
      "Epoch 5/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 46670.0312 - accuracy: 0.3783\n",
      "Epoch 6/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 43422.3828 - accuracy: 0.3812\n",
      "Epoch 7/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 40130.2461 - accuracy: 0.3848\n",
      "Epoch 8/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 36748.0430 - accuracy: 0.3851\n",
      "Epoch 9/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 33341.7734 - accuracy: 0.3902\n",
      "Epoch 10/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 30174.5781 - accuracy: 0.3967\n",
      "Epoch 11/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 26939.7793 - accuracy: 0.4036\n",
      "Epoch 12/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 23605.6582 - accuracy: 0.4106\n",
      "Epoch 13/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 20245.3984 - accuracy: 0.4143\n",
      "Epoch 14/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 16830.2500 - accuracy: 0.4329\n",
      "Epoch 15/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 13414.1201 - accuracy: 0.4539\n",
      "Epoch 16/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 10467.1514 - accuracy: 0.4762\n",
      "Epoch 17/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 7406.3438 - accuracy: 0.4954\n",
      "Epoch 18/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4241.3643 - accuracy: 0.5162\n",
      "Epoch 19/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 1099.2036 - accuracy: 0.5718\n",
      "Epoch 20/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 66.2052 - accuracy: 0.6475\n",
      "Epoch 21/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 64.1023 - accuracy: 0.6600\n",
      "Epoch 22/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 63.8594 - accuracy: 0.6648\n",
      "Epoch 23/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 61.4234 - accuracy: 0.6642\n",
      "Epoch 24/450\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 61.5751 - accuracy: 0.6735\n",
      "Epoch 25/450\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 58.7776 - accuracy: 0.6739\n",
      "Epoch 26/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 58.3051 - accuracy: 0.6749\n",
      "Epoch 27/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 55.4700 - accuracy: 0.6787\n",
      "Epoch 28/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 55.8406 - accuracy: 0.6742\n",
      "Epoch 29/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 54.1359 - accuracy: 0.6754\n",
      "Epoch 30/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 52.3180 - accuracy: 0.6752\n",
      "Epoch 31/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 49.5275 - accuracy: 0.6817\n",
      "Epoch 32/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 49.6284 - accuracy: 0.6777\n",
      "Epoch 33/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 46.9945 - accuracy: 0.6785\n",
      "Epoch 34/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 46.2066 - accuracy: 0.6847\n",
      "Epoch 35/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 47.5936 - accuracy: 0.6858\n",
      "Epoch 36/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 43.1131 - accuracy: 0.6853\n",
      "Epoch 37/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 41.1971 - accuracy: 0.6908\n",
      "Epoch 38/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 39.4279 - accuracy: 0.6910\n",
      "Epoch 39/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 39.5752 - accuracy: 0.6933\n",
      "Epoch 40/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 37.6495 - accuracy: 0.6930\n",
      "Epoch 41/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 36.6221 - accuracy: 0.6935\n",
      "Epoch 42/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 35.8321 - accuracy: 0.6960\n",
      "Epoch 43/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 33.1839 - accuracy: 0.6988\n",
      "Epoch 44/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 32.2764 - accuracy: 0.7007\n",
      "Epoch 45/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 29.7289 - accuracy: 0.7045\n",
      "Epoch 46/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 29.3183 - accuracy: 0.7064\n",
      "Epoch 47/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 28.2829 - accuracy: 0.7102\n",
      "Epoch 48/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 25.7916 - accuracy: 0.7120\n",
      "Epoch 49/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 24.5076 - accuracy: 0.7139\n",
      "Epoch 50/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 25.2053 - accuracy: 0.7140\n",
      "Epoch 51/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 23.8513 - accuracy: 0.7169\n",
      "Epoch 52/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 22.8311 - accuracy: 0.7208\n",
      "Epoch 53/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 25.7246 - accuracy: 0.7209\n",
      "Epoch 54/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 19.1528 - accuracy: 0.7228\n",
      "Epoch 55/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 17.8994 - accuracy: 0.7285\n",
      "Epoch 56/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 16.4721 - accuracy: 0.7314\n",
      "Epoch 57/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 15.1021 - accuracy: 0.7279\n",
      "Epoch 58/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 15.4185 - accuracy: 0.7327\n",
      "Epoch 59/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 13.1990 - accuracy: 0.7370\n",
      "Epoch 60/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 12.5221 - accuracy: 0.7305\n",
      "Epoch 61/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 11.3972 - accuracy: 0.7332\n",
      "Epoch 62/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 10.5285 - accuracy: 0.7342\n",
      "Epoch 63/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 11.7546 - accuracy: 0.7289\n",
      "Epoch 64/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 13.2350 - accuracy: 0.7272\n",
      "Epoch 65/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 7.5757 - accuracy: 0.7269\n",
      "Epoch 66/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 6.8016 - accuracy: 0.7307\n",
      "Epoch 67/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 7.3949 - accuracy: 0.7209\n",
      "Epoch 68/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 7.2093 - accuracy: 0.7299\n",
      "Epoch 69/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 7.1103 - accuracy: 0.7344\n",
      "Epoch 70/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.7736 - accuracy: 0.7448\n",
      "Epoch 71/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.3137 - accuracy: 0.7450\n",
      "Epoch 72/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.8927 - accuracy: 0.7462\n",
      "Epoch 73/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 6.8452 - accuracy: 0.7515\n",
      "Epoch 74/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.6819 - accuracy: 0.7525\n",
      "Epoch 75/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.6015 - accuracy: 0.7535\n",
      "Epoch 76/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 8.7675 - accuracy: 0.7503\n",
      "Epoch 77/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 5.6480 - accuracy: 0.7609\n",
      "Epoch 78/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.3594 - accuracy: 0.7593\n",
      "Epoch 79/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.7442 - accuracy: 0.7660\n",
      "Epoch 80/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.0488 - accuracy: 0.7630\n",
      "Epoch 81/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.6622 - accuracy: 0.7637\n",
      "Epoch 82/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.6154 - accuracy: 0.7652\n",
      "Epoch 83/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.7835 - accuracy: 0.7737\n",
      "Epoch 84/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.0535 - accuracy: 0.7727\n",
      "Epoch 85/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.6456 - accuracy: 0.7734\n",
      "Epoch 86/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.9797 - accuracy: 0.7820\n",
      "Epoch 87/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 8.9466 - accuracy: 0.7704\n",
      "Epoch 88/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.2908 - accuracy: 0.7787\n",
      "Epoch 89/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.3274 - accuracy: 0.7777\n",
      "Epoch 90/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.4700 - accuracy: 0.7755\n",
      "Epoch 91/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 7.0101 - accuracy: 0.7809\n",
      "Epoch 92/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 10.4916 - accuracy: 0.7738\n",
      "Epoch 93/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.3337 - accuracy: 0.7808\n",
      "Epoch 94/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.3866 - accuracy: 0.7854\n",
      "Epoch 95/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.6571 - accuracy: 0.7884\n",
      "Epoch 96/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.1738 - accuracy: 0.7887\n",
      "Epoch 97/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.5704 - accuracy: 0.7863\n",
      "Epoch 98/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.4916 - accuracy: 0.7845\n",
      "Epoch 99/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.0924 - accuracy: 0.7873\n",
      "Epoch 100/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.6522 - accuracy: 0.7898\n",
      "Epoch 101/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 7.0134 - accuracy: 0.7862\n",
      "Epoch 102/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.1610 - accuracy: 0.7898\n",
      "Epoch 103/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.2653 - accuracy: 0.7997\n",
      "Epoch 104/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.9565 - accuracy: 0.7929\n",
      "Epoch 105/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.4737 - accuracy: 0.7927\n",
      "Epoch 106/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.9499 - accuracy: 0.8016\n",
      "Epoch 107/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.3491 - accuracy: 0.7959\n",
      "Epoch 108/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.6943 - accuracy: 0.7915\n",
      "Epoch 109/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.9682 - accuracy: 0.7970\n",
      "Epoch 110/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.6031 - accuracy: 0.8004\n",
      "Epoch 111/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7984 - accuracy: 0.8068\n",
      "Epoch 112/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 7.5599 - accuracy: 0.7953\n",
      "Epoch 113/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.4756 - accuracy: 0.8013\n",
      "Epoch 114/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 6.2165 - accuracy: 0.7983\n",
      "Epoch 115/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.5902 - accuracy: 0.8065\n",
      "Epoch 116/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.3858 - accuracy: 0.8000\n",
      "Epoch 117/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.1724 - accuracy: 0.8041\n",
      "Epoch 118/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7419 - accuracy: 0.8088\n",
      "Epoch 119/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 12.1421 - accuracy: 0.7954\n",
      "Epoch 120/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.1234 - accuracy: 0.8094\n",
      "Epoch 121/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.0572 - accuracy: 0.8048\n",
      "Epoch 122/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.8208 - accuracy: 0.8005\n",
      "Epoch 123/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.1433 - accuracy: 0.8083\n",
      "Epoch 124/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.6406 - accuracy: 0.8055\n",
      "Epoch 125/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 5.2570 - accuracy: 0.8018\n",
      "Epoch 126/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 11.1569 - accuracy: 0.8030\n",
      "Epoch 127/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.6315 - accuracy: 0.7977\n",
      "Epoch 128/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.9288 - accuracy: 0.8065\n",
      "Epoch 129/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 14.1984 - accuracy: 0.7968\n",
      "Epoch 130/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.2196 - accuracy: 0.8130\n",
      "Epoch 131/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.4787 - accuracy: 0.8106\n",
      "Epoch 132/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.6069 - accuracy: 0.7997\n",
      "Epoch 133/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.9808 - accuracy: 0.8035\n",
      "Epoch 134/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.8334 - accuracy: 0.8074\n",
      "Epoch 135/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.9099 - accuracy: 0.8176\n",
      "Epoch 136/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.8077 - accuracy: 0.8148\n",
      "Epoch 137/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 5.2337 - accuracy: 0.8069\n",
      "Epoch 138/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.0564 - accuracy: 0.8113\n",
      "Epoch 139/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.6652 - accuracy: 0.8060\n",
      "Epoch 140/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.5964 - accuracy: 0.8093\n",
      "Epoch 141/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 5.7264 - accuracy: 0.8184\n",
      "Epoch 142/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.6621 - accuracy: 0.8178\n",
      "Epoch 143/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.1442 - accuracy: 0.8091\n",
      "Epoch 144/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.9128 - accuracy: 0.8105\n",
      "Epoch 145/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.9674 - accuracy: 0.8051\n",
      "Epoch 146/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 15.8905 - accuracy: 0.8106\n",
      "Epoch 147/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.4127 - accuracy: 0.8128\n",
      "Epoch 148/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.4307 - accuracy: 0.8128\n",
      "Epoch 149/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 5.1666 - accuracy: 0.8133\n",
      "Epoch 150/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.0423 - accuracy: 0.8134\n",
      "Epoch 151/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.8893 - accuracy: 0.8160\n",
      "Epoch 152/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.9992 - accuracy: 0.8161\n",
      "Epoch 153/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.7220 - accuracy: 0.8140\n",
      "Epoch 154/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.9358 - accuracy: 0.8088\n",
      "Epoch 155/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1761 - accuracy: 0.8209\n",
      "Epoch 156/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.9547 - accuracy: 0.8099\n",
      "Epoch 157/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.6487 - accuracy: 0.8088\n",
      "Epoch 158/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.9163 - accuracy: 0.8145\n",
      "Epoch 159/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1677 - accuracy: 0.8203\n",
      "Epoch 160/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.8625 - accuracy: 0.8134\n",
      "Epoch 161/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.9039 - accuracy: 0.8111\n",
      "Epoch 162/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.4932 - accuracy: 0.8103\n",
      "Epoch 163/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.1838 - accuracy: 0.8206\n",
      "Epoch 164/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.0921 - accuracy: 0.8153\n",
      "Epoch 165/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.8942 - accuracy: 0.8234\n",
      "Epoch 166/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.5088 - accuracy: 0.8203\n",
      "Epoch 167/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.7872 - accuracy: 0.8041\n",
      "Epoch 168/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.8918 - accuracy: 0.8183\n",
      "Epoch 169/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1415 - accuracy: 0.8170\n",
      "Epoch 170/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.8648 - accuracy: 0.8109\n",
      "Epoch 171/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.7078 - accuracy: 0.8195\n",
      "Epoch 172/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.7288 - accuracy: 0.8125\n",
      "Epoch 173/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.3889 - accuracy: 0.8161\n",
      "Epoch 174/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.4079 - accuracy: 0.8154\n",
      "Epoch 175/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.5417 - accuracy: 0.8150\n",
      "Epoch 176/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1789 - accuracy: 0.8258\n",
      "Epoch 177/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7042 - accuracy: 0.8151\n",
      "Epoch 178/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.8684 - accuracy: 0.8248\n",
      "Epoch 179/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.7680 - accuracy: 0.8163\n",
      "Epoch 180/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.4905 - accuracy: 0.8093\n",
      "Epoch 181/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 8.6729 - accuracy: 0.8043\n",
      "Epoch 182/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.4025 - accuracy: 0.8176\n",
      "Epoch 183/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.0947 - accuracy: 0.8168\n",
      "Epoch 184/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.8136 - accuracy: 0.8199\n",
      "Epoch 185/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.0031 - accuracy: 0.8059\n",
      "Epoch 186/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.9253 - accuracy: 0.8089\n",
      "Epoch 187/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.0910 - accuracy: 0.8185\n",
      "Epoch 188/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.5782 - accuracy: 0.8184\n",
      "Epoch 189/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.1852 - accuracy: 0.8146\n",
      "Epoch 190/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.2340 - accuracy: 0.8204\n",
      "Epoch 191/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.4139 - accuracy: 0.8121\n",
      "Epoch 192/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.2420 - accuracy: 0.8093\n",
      "Epoch 193/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 18.4526 - accuracy: 0.7973\n",
      "Epoch 194/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.0499 - accuracy: 0.8128\n",
      "Epoch 195/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.3905 - accuracy: 0.8155\n",
      "Epoch 196/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1081 - accuracy: 0.8233\n",
      "Epoch 197/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.2468 - accuracy: 0.8139\n",
      "Epoch 198/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.9513 - accuracy: 0.8121\n",
      "Epoch 199/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.1110 - accuracy: 0.8203\n",
      "Epoch 200/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.4668 - accuracy: 0.8166\n",
      "Epoch 201/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.5716 - accuracy: 0.8181\n",
      "Epoch 202/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.9314 - accuracy: 0.8151\n",
      "Epoch 203/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.7011 - accuracy: 0.8171\n",
      "Epoch 204/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.1834 - accuracy: 0.8166\n",
      "Epoch 205/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.2158 - accuracy: 0.8198\n",
      "Epoch 206/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.4104 - accuracy: 0.8164\n",
      "Epoch 207/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1848 - accuracy: 0.8221\n",
      "Epoch 208/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.0647 - accuracy: 0.8150\n",
      "Epoch 209/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.2443 - accuracy: 0.8159\n",
      "Epoch 210/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.8206 - accuracy: 0.8179\n",
      "Epoch 211/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.4048 - accuracy: 0.8125\n",
      "Epoch 212/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.6439 - accuracy: 0.8234\n",
      "Epoch 213/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.3513 - accuracy: 0.8200\n",
      "Epoch 214/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1927 - accuracy: 0.8195\n",
      "Epoch 215/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.7065 - accuracy: 0.8139\n",
      "Epoch 216/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1022 - accuracy: 0.8218\n",
      "Epoch 217/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.7042 - accuracy: 0.8156\n",
      "Epoch 218/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 5.0581 - accuracy: 0.8136\n",
      "Epoch 219/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.8724 - accuracy: 0.8194\n",
      "Epoch 220/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.5049 - accuracy: 0.8201\n",
      "Epoch 221/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.0839 - accuracy: 0.8156\n",
      "Epoch 222/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.6775 - accuracy: 0.8114\n",
      "Epoch 223/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.5625 - accuracy: 0.8229\n",
      "Epoch 224/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7012 - accuracy: 0.8184\n",
      "Epoch 225/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1426 - accuracy: 0.8213\n",
      "Epoch 226/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.8665 - accuracy: 0.8190\n",
      "Epoch 227/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.0980 - accuracy: 0.8246\n",
      "Epoch 228/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.7372 - accuracy: 0.8155\n",
      "Epoch 229/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.9120 - accuracy: 0.8135\n",
      "Epoch 230/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.5607 - accuracy: 0.8279\n",
      "Epoch 231/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.2466 - accuracy: 0.8211\n",
      "Epoch 232/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.0699 - accuracy: 0.8270\n",
      "Epoch 233/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 15.1477 - accuracy: 0.8108\n",
      "Epoch 234/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7332 - accuracy: 0.8209\n",
      "Epoch 235/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.0249 - accuracy: 0.8260\n",
      "Epoch 236/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.0313 - accuracy: 0.8165\n",
      "Epoch 237/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 5.6083 - accuracy: 0.8100\n",
      "Epoch 238/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.1138 - accuracy: 0.8200\n",
      "Epoch 239/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.9023 - accuracy: 0.8221\n",
      "Epoch 240/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.0370 - accuracy: 0.8121\n",
      "Epoch 241/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.5332 - accuracy: 0.8284\n",
      "Epoch 242/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.5585 - accuracy: 0.8195\n",
      "Epoch 243/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 7.6114 - accuracy: 0.8109\n",
      "Epoch 244/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.0398 - accuracy: 0.8203\n",
      "Epoch 245/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.8558 - accuracy: 0.8236\n",
      "Epoch 246/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.4676 - accuracy: 0.8191\n",
      "Epoch 247/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.8101 - accuracy: 0.8134\n",
      "Epoch 248/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.7712 - accuracy: 0.8293\n",
      "Epoch 249/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.3460 - accuracy: 0.8175\n",
      "Epoch 250/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.9424 - accuracy: 0.8204\n",
      "Epoch 251/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.8136 - accuracy: 0.8135\n",
      "Epoch 252/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.2898 - accuracy: 0.8246\n",
      "Epoch 253/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.8056 - accuracy: 0.8159\n",
      "Epoch 254/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 2.9815 - accuracy: 0.8218\n",
      "Epoch 255/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.8561 - accuracy: 0.8270\n",
      "Epoch 256/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.9275 - accuracy: 0.8154\n",
      "Epoch 257/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.2516 - accuracy: 0.8131\n",
      "Epoch 258/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.5189 - accuracy: 0.8180\n",
      "Epoch 259/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.9147 - accuracy: 0.8219\n",
      "Epoch 260/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.5880 - accuracy: 0.8223\n",
      "Epoch 261/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.0456 - accuracy: 0.8221\n",
      "Epoch 262/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.3430 - accuracy: 0.8230\n",
      "Epoch 263/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 5.3627 - accuracy: 0.8228\n",
      "Epoch 264/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.4700 - accuracy: 0.8268\n",
      "Epoch 265/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.8774 - accuracy: 0.8209\n",
      "Epoch 266/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.2307 - accuracy: 0.8293\n",
      "Epoch 267/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.8397 - accuracy: 0.8193\n",
      "Epoch 268/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.5768 - accuracy: 0.8165\n",
      "Epoch 269/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.0084 - accuracy: 0.8204\n",
      "Epoch 270/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.4658 - accuracy: 0.8325\n",
      "Epoch 271/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 5.1014 - accuracy: 0.8139\n",
      "Epoch 272/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1149 - accuracy: 0.8308\n",
      "Epoch 273/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.5438 - accuracy: 0.8219\n",
      "Epoch 274/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 20.5880 - accuracy: 0.8108\n",
      "Epoch 275/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.9119 - accuracy: 0.8278\n",
      "Epoch 276/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.6051 - accuracy: 0.8225\n",
      "Epoch 277/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.3059 - accuracy: 0.8216\n",
      "Epoch 278/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.8509 - accuracy: 0.8288\n",
      "Epoch 279/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.6631 - accuracy: 0.8253\n",
      "Epoch 280/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 2.2096 - accuracy: 0.8348\n",
      "Epoch 281/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.8270 - accuracy: 0.8299\n",
      "Epoch 282/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.8886 - accuracy: 0.8221\n",
      "Epoch 283/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.5860 - accuracy: 0.8281\n",
      "Epoch 284/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.2325 - accuracy: 0.8224\n",
      "Epoch 285/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.4732 - accuracy: 0.8240\n",
      "Epoch 286/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.0800 - accuracy: 0.8246\n",
      "Epoch 287/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.4813 - accuracy: 0.8310\n",
      "Epoch 288/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 6.0588 - accuracy: 0.8148\n",
      "Epoch 289/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.3696 - accuracy: 0.8321\n",
      "Epoch 290/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7880 - accuracy: 0.8275\n",
      "Epoch 291/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.9005 - accuracy: 0.8115\n",
      "Epoch 292/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.6215 - accuracy: 0.8228\n",
      "Epoch 293/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.5465 - accuracy: 0.8254\n",
      "Epoch 294/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.1619 - accuracy: 0.8240\n",
      "Epoch 295/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7374 - accuracy: 0.8233\n",
      "Epoch 296/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 6.0449 - accuracy: 0.8115\n",
      "Epoch 297/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.0049 - accuracy: 0.8291\n",
      "Epoch 298/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.9833 - accuracy: 0.8279\n",
      "Epoch 299/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.6082 - accuracy: 0.8315\n",
      "Epoch 300/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.1265 - accuracy: 0.8226\n",
      "Epoch 301/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1862 - accuracy: 0.8275\n",
      "Epoch 302/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.8401 - accuracy: 0.8298\n",
      "Epoch 303/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.3160 - accuracy: 0.8214\n",
      "Epoch 304/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 5.2887 - accuracy: 0.8170\n",
      "Epoch 305/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.3097 - accuracy: 0.8239\n",
      "Epoch 306/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7267 - accuracy: 0.8269\n",
      "Epoch 307/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.8723 - accuracy: 0.8196\n",
      "Epoch 308/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.3833 - accuracy: 0.8221\n",
      "Epoch 309/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.4730 - accuracy: 0.8301\n",
      "Epoch 310/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1162 - accuracy: 0.8244\n",
      "Epoch 311/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.1510 - accuracy: 0.8205\n",
      "Epoch 312/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 2.3608 - accuracy: 0.8334\n",
      "Epoch 313/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 12.8776 - accuracy: 0.8179\n",
      "Epoch 314/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.3723 - accuracy: 0.8271\n",
      "Epoch 315/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.5734 - accuracy: 0.8259\n",
      "Epoch 316/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7145 - accuracy: 0.8233\n",
      "Epoch 317/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.6550 - accuracy: 0.8290\n",
      "Epoch 318/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.4428 - accuracy: 0.8241\n",
      "Epoch 319/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.3751 - accuracy: 0.8338\n",
      "Epoch 320/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1881 - accuracy: 0.8328\n",
      "Epoch 321/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7595 - accuracy: 0.8269\n",
      "Epoch 322/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.4495 - accuracy: 0.8230\n",
      "Epoch 323/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.1910 - accuracy: 0.8190\n",
      "Epoch 324/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.5965 - accuracy: 0.8306\n",
      "Epoch 325/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.7678 - accuracy: 0.8299\n",
      "Epoch 326/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7825 - accuracy: 0.8249\n",
      "Epoch 327/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.6923 - accuracy: 0.8239\n",
      "Epoch 328/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1864 - accuracy: 0.8249\n",
      "Epoch 329/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.8140 - accuracy: 0.8305\n",
      "Epoch 330/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.3160 - accuracy: 0.8310\n",
      "Epoch 331/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.7921 - accuracy: 0.8329\n",
      "Epoch 332/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.3856 - accuracy: 0.8280\n",
      "Epoch 333/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.6248 - accuracy: 0.8269\n",
      "Epoch 334/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.0504 - accuracy: 0.8355\n",
      "Epoch 335/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.3388 - accuracy: 0.8201\n",
      "Epoch 336/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.4954 - accuracy: 0.8288\n",
      "Epoch 337/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.4464 - accuracy: 0.8244\n",
      "Epoch 338/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.0854 - accuracy: 0.8251\n",
      "Epoch 339/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.5956 - accuracy: 0.8258\n",
      "Epoch 340/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.7643 - accuracy: 0.8184\n",
      "Epoch 341/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 7.3448 - accuracy: 0.8180\n",
      "Epoch 342/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.0806 - accuracy: 0.8339\n",
      "Epoch 343/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1877 - accuracy: 0.8326\n",
      "Epoch 344/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.7232 - accuracy: 0.8314\n",
      "Epoch 345/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.6544 - accuracy: 0.8271\n",
      "Epoch 346/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.9172 - accuracy: 0.8273\n",
      "Epoch 347/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.7903 - accuracy: 0.8269\n",
      "Epoch 348/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.1020 - accuracy: 0.8215\n",
      "Epoch 349/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.9614 - accuracy: 0.8214\n",
      "Epoch 350/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.0112 - accuracy: 0.8339\n",
      "Epoch 351/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.9801 - accuracy: 0.8240\n",
      "Epoch 352/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1050 - accuracy: 0.8260\n",
      "Epoch 353/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.4036 - accuracy: 0.8384\n",
      "Epoch 354/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.3423 - accuracy: 0.8225\n",
      "Epoch 355/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.6083 - accuracy: 0.8229\n",
      "Epoch 356/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.3698 - accuracy: 0.8249\n",
      "Epoch 357/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.2254 - accuracy: 0.8223\n",
      "Epoch 358/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.6858 - accuracy: 0.8286\n",
      "Epoch 359/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.5789 - accuracy: 0.8318\n",
      "Epoch 360/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7490 - accuracy: 0.8295\n",
      "Epoch 361/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1036 - accuracy: 0.8291\n",
      "Epoch 362/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.7986 - accuracy: 0.8268\n",
      "Epoch 363/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.1128 - accuracy: 0.8251\n",
      "Epoch 364/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.3240 - accuracy: 0.8260\n",
      "Epoch 365/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.9213 - accuracy: 0.8293\n",
      "Epoch 366/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.3562 - accuracy: 0.8261\n",
      "Epoch 367/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 6.8674 - accuracy: 0.8135\n",
      "Epoch 368/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.3002 - accuracy: 0.8303\n",
      "Epoch 369/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.2870 - accuracy: 0.8289\n",
      "Epoch 370/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.9574 - accuracy: 0.8276\n",
      "Epoch 371/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.2792 - accuracy: 0.8270\n",
      "Epoch 372/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7195 - accuracy: 0.8244\n",
      "Epoch 373/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 7.3314 - accuracy: 0.8138\n",
      "Epoch 374/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.4927 - accuracy: 0.8314\n",
      "Epoch 375/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 2.9009 - accuracy: 0.8350\n",
      "Epoch 376/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.0835 - accuracy: 0.8224\n",
      "Epoch 377/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 15.8718 - accuracy: 0.8180\n",
      "Epoch 378/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.8625 - accuracy: 0.8373\n",
      "Epoch 379/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.5342 - accuracy: 0.8288\n",
      "Epoch 380/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.8375 - accuracy: 0.8411\n",
      "Epoch 381/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.5485 - accuracy: 0.8316\n",
      "Epoch 382/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.0292 - accuracy: 0.8356\n",
      "Epoch 383/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.6957 - accuracy: 0.8354\n",
      "Epoch 384/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.6906 - accuracy: 0.8385\n",
      "Epoch 385/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.9628 - accuracy: 0.8229\n",
      "Epoch 386/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.6811 - accuracy: 0.8285\n",
      "Epoch 387/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.3283 - accuracy: 0.8341\n",
      "Epoch 388/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.2813 - accuracy: 0.8318\n",
      "Epoch 389/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.4881 - accuracy: 0.8268\n",
      "Epoch 390/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7033 - accuracy: 0.8274\n",
      "Epoch 391/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.1105 - accuracy: 0.8338\n",
      "Epoch 392/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.2162 - accuracy: 0.8348\n",
      "Epoch 393/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.7749 - accuracy: 0.8351\n",
      "Epoch 394/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 4.1929 - accuracy: 0.8286\n",
      "Epoch 395/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.3512 - accuracy: 0.8318\n",
      "Epoch 396/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.7277 - accuracy: 0.8298\n",
      "Epoch 397/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.6136 - accuracy: 0.8320\n",
      "Epoch 398/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.2243 - accuracy: 0.8320\n",
      "Epoch 399/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.5749 - accuracy: 0.8226\n",
      "Epoch 400/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.3673 - accuracy: 0.8319\n",
      "Epoch 401/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.6355 - accuracy: 0.8321\n",
      "Epoch 402/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.2831 - accuracy: 0.8391\n",
      "Epoch 403/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 2.8165 - accuracy: 0.8383\n",
      "Epoch 404/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.7176 - accuracy: 0.8389\n",
      "Epoch 405/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.3307 - accuracy: 0.8311\n",
      "Epoch 406/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.0619 - accuracy: 0.8394\n",
      "Epoch 407/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.3506 - accuracy: 0.8286\n",
      "Epoch 408/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.4549 - accuracy: 0.8334\n",
      "Epoch 409/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 14.5537 - accuracy: 0.8303\n",
      "Epoch 410/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.3447 - accuracy: 0.8340\n",
      "Epoch 411/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.8033 - accuracy: 0.8398\n",
      "Epoch 412/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1972 - accuracy: 0.8389\n",
      "Epoch 413/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.5427 - accuracy: 0.8318\n",
      "Epoch 414/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.4138 - accuracy: 0.8374\n",
      "Epoch 415/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.0752 - accuracy: 0.8385\n",
      "Epoch 416/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.8834 - accuracy: 0.8380\n",
      "Epoch 417/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 6.4157 - accuracy: 0.8174\n",
      "Epoch 418/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.7406 - accuracy: 0.8420\n",
      "Epoch 419/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.7255 - accuracy: 0.8315\n",
      "Epoch 420/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.9052 - accuracy: 0.8383\n",
      "Epoch 421/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.5893 - accuracy: 0.8333\n",
      "Epoch 422/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.7126 - accuracy: 0.8278\n",
      "Epoch 423/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.2151 - accuracy: 0.8378\n",
      "Epoch 424/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.9856 - accuracy: 0.8358\n",
      "Epoch 425/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 2.8191 - accuracy: 0.8368\n",
      "Epoch 426/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.6100 - accuracy: 0.8298\n",
      "Epoch 427/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.8629 - accuracy: 0.8385\n",
      "Epoch 428/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.5917 - accuracy: 0.8335\n",
      "Epoch 429/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.0914 - accuracy: 0.8370\n",
      "Epoch 430/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.4181 - accuracy: 0.8324\n",
      "Epoch 431/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 5.0425 - accuracy: 0.8293\n",
      "Epoch 432/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.6737 - accuracy: 0.8371\n",
      "Epoch 433/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.3976 - accuracy: 0.8400\n",
      "Epoch 434/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.8526 - accuracy: 0.8318\n",
      "Epoch 435/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 2.6457 - accuracy: 0.8423\n",
      "Epoch 436/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.7022 - accuracy: 0.8361\n",
      "Epoch 437/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.1994 - accuracy: 0.8288\n",
      "Epoch 438/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.3602 - accuracy: 0.8406\n",
      "Epoch 439/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.9970 - accuracy: 0.8363\n",
      "Epoch 440/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 1.9314 - accuracy: 0.8521\n",
      "Epoch 441/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.1310 - accuracy: 0.8385\n",
      "Epoch 442/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.8619 - accuracy: 0.8418\n",
      "Epoch 443/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 5.0041 - accuracy: 0.8303\n",
      "Epoch 444/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.8418 - accuracy: 0.8348\n",
      "Epoch 445/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.3101 - accuracy: 0.8340\n",
      "Epoch 446/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 3.4697 - accuracy: 0.8385\n",
      "Epoch 447/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.9736 - accuracy: 0.8395\n",
      "Epoch 448/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 4.2914 - accuracy: 0.8350\n",
      "Epoch 449/450\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 2.6319 - accuracy: 0.8446\n",
      "Epoch 450/450\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 3.8750 - accuracy: 0.8315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x262b18a5190>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units=18, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=2, activation=\"linear\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "NN_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.00001),\n",
    "    metrics= [\"accuracy\"]\n",
    ")\n",
    "\n",
    "NN_model.fit(X_train, Y_train, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 0s 1ms/step - loss: 2.7933 - accuracy: 0.8349\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = NN_model.evaluate(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 1ms/step - loss: 3.1057 - accuracy: 0.8215\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = NN_model.evaluate(X_cv, Y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_params = [\n",
    "    {\n",
    "        \"max_depth\" : [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 25],\n",
    "        \"n_estimators\" : [50, 100, 150, 175, 200],\n",
    "        \"eta\" : [0.01, 0.1, 0.2, 0.3, 0.5],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;eta&#x27;: [0.01, 0.1, 0.2, 0.3, 0.5],\n",
       "                          &#x27;max_depth&#x27;: [2, 4, 5, 6, 8, 10, 11, 12, 14, 16, 18,\n",
       "                                        20, 21, 25],\n",
       "                          &#x27;n_estimators&#x27;: [50, 100, 150, 175, 200]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;eta&#x27;: [0.01, 0.1, 0.2, 0.3, 0.5],\n",
       "                          &#x27;max_depth&#x27;: [2, 4, 5, 6, 8, 10, 11, 12, 14, 16, 18,\n",
       "                                        20, 21, 25],\n",
       "                          &#x27;n_estimators&#x27;: [50, 100, 150, 175, 200]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'eta': [0.01, 0.1, 0.2, 0.3, 0.5],\n",
       "                          'max_depth': [2, 4, 5, 6, 8, 10, 11, 12, 14, 16, 18,\n",
       "                                        20, 21, 25],\n",
       "                          'n_estimators': [50, 100, 150, 175, 200]}])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv_xgbc = GridSearchCV(xgbc_model, xgbc_params, cv=5, n_jobs=-1)\n",
    "gs_cv_xgbc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eta': 0.1, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(gs_cv_xgbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(eta=0.1, max_depth=5, n_estimators=200, verbose=1, n_jobs=-1, num_parallel_tree=6, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.62387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalidation_0-logloss:0.56748\n",
      "[2]\tvalidation_0-logloss:0.51958\n",
      "[3]\tvalidation_0-logloss:0.47944\n",
      "[4]\tvalidation_0-logloss:0.44522\n",
      "[5]\tvalidation_0-logloss:0.41549\n",
      "[6]\tvalidation_0-logloss:0.38903\n",
      "[7]\tvalidation_0-logloss:0.36535\n",
      "[8]\tvalidation_0-logloss:0.34487\n",
      "[9]\tvalidation_0-logloss:0.32699\n",
      "[10]\tvalidation_0-logloss:0.31117\n",
      "[11]\tvalidation_0-logloss:0.29688\n",
      "[12]\tvalidation_0-logloss:0.28432\n",
      "[13]\tvalidation_0-logloss:0.27347\n",
      "[14]\tvalidation_0-logloss:0.26343\n",
      "[15]\tvalidation_0-logloss:0.25414\n",
      "[16]\tvalidation_0-logloss:0.24633\n",
      "[17]\tvalidation_0-logloss:0.23896\n",
      "[18]\tvalidation_0-logloss:0.23195\n",
      "[19]\tvalidation_0-logloss:0.22602\n",
      "[20]\tvalidation_0-logloss:0.22090\n",
      "[21]\tvalidation_0-logloss:0.21626\n",
      "[22]\tvalidation_0-logloss:0.21135\n",
      "[23]\tvalidation_0-logloss:0.20618\n",
      "[24]\tvalidation_0-logloss:0.20188\n",
      "[25]\tvalidation_0-logloss:0.19776\n",
      "[26]\tvalidation_0-logloss:0.19419\n",
      "[27]\tvalidation_0-logloss:0.19088\n",
      "[28]\tvalidation_0-logloss:0.18826\n",
      "[29]\tvalidation_0-logloss:0.18564\n",
      "[30]\tvalidation_0-logloss:0.18287\n",
      "[31]\tvalidation_0-logloss:0.17998\n",
      "[32]\tvalidation_0-logloss:0.17798\n",
      "[33]\tvalidation_0-logloss:0.17571\n",
      "[34]\tvalidation_0-logloss:0.17325\n",
      "[35]\tvalidation_0-logloss:0.17097\n",
      "[36]\tvalidation_0-logloss:0.16882\n",
      "[37]\tvalidation_0-logloss:0.16596\n",
      "[38]\tvalidation_0-logloss:0.16414\n",
      "[39]\tvalidation_0-logloss:0.16213\n",
      "[40]\tvalidation_0-logloss:0.16018\n",
      "[41]\tvalidation_0-logloss:0.15915\n",
      "[42]\tvalidation_0-logloss:0.15769\n",
      "[43]\tvalidation_0-logloss:0.15640\n",
      "[44]\tvalidation_0-logloss:0.15531\n",
      "[45]\tvalidation_0-logloss:0.15429\n",
      "[46]\tvalidation_0-logloss:0.15314\n",
      "[47]\tvalidation_0-logloss:0.15156\n",
      "[48]\tvalidation_0-logloss:0.15051\n",
      "[49]\tvalidation_0-logloss:0.14909\n",
      "[50]\tvalidation_0-logloss:0.14809\n",
      "[51]\tvalidation_0-logloss:0.14756\n",
      "[52]\tvalidation_0-logloss:0.14679\n",
      "[53]\tvalidation_0-logloss:0.14612\n",
      "[54]\tvalidation_0-logloss:0.14541\n",
      "[55]\tvalidation_0-logloss:0.14448\n",
      "[56]\tvalidation_0-logloss:0.14348\n",
      "[57]\tvalidation_0-logloss:0.14240\n",
      "[58]\tvalidation_0-logloss:0.14085\n",
      "[59]\tvalidation_0-logloss:0.14010\n",
      "[60]\tvalidation_0-logloss:0.13953\n",
      "[61]\tvalidation_0-logloss:0.13928\n",
      "[62]\tvalidation_0-logloss:0.13844\n",
      "[63]\tvalidation_0-logloss:0.13795\n",
      "[64]\tvalidation_0-logloss:0.13716\n",
      "[65]\tvalidation_0-logloss:0.13697\n",
      "[66]\tvalidation_0-logloss:0.13598\n",
      "[67]\tvalidation_0-logloss:0.13538\n",
      "[68]\tvalidation_0-logloss:0.13502\n",
      "[69]\tvalidation_0-logloss:0.13440\n",
      "[70]\tvalidation_0-logloss:0.13373\n",
      "[71]\tvalidation_0-logloss:0.13319\n",
      "[72]\tvalidation_0-logloss:0.13302\n",
      "[73]\tvalidation_0-logloss:0.13275\n",
      "[74]\tvalidation_0-logloss:0.13244\n",
      "[75]\tvalidation_0-logloss:0.13191\n",
      "[76]\tvalidation_0-logloss:0.13072\n",
      "[77]\tvalidation_0-logloss:0.12977\n",
      "[78]\tvalidation_0-logloss:0.12952\n",
      "[79]\tvalidation_0-logloss:0.12931\n",
      "[80]\tvalidation_0-logloss:0.12905\n",
      "[81]\tvalidation_0-logloss:0.12865\n",
      "[82]\tvalidation_0-logloss:0.12809\n",
      "[83]\tvalidation_0-logloss:0.12798\n",
      "[84]\tvalidation_0-logloss:0.12776\n",
      "[85]\tvalidation_0-logloss:0.12659\n",
      "[86]\tvalidation_0-logloss:0.12625\n",
      "[87]\tvalidation_0-logloss:0.12531\n",
      "[88]\tvalidation_0-logloss:0.12467\n",
      "[89]\tvalidation_0-logloss:0.12424\n",
      "[90]\tvalidation_0-logloss:0.12406\n",
      "[91]\tvalidation_0-logloss:0.12367\n",
      "[92]\tvalidation_0-logloss:0.12289\n",
      "[93]\tvalidation_0-logloss:0.12280\n",
      "[94]\tvalidation_0-logloss:0.12265\n",
      "[95]\tvalidation_0-logloss:0.12235\n",
      "[96]\tvalidation_0-logloss:0.12177\n",
      "[97]\tvalidation_0-logloss:0.12146\n",
      "[98]\tvalidation_0-logloss:0.12110\n",
      "[99]\tvalidation_0-logloss:0.12099\n",
      "[100]\tvalidation_0-logloss:0.12108\n",
      "[101]\tvalidation_0-logloss:0.12058\n",
      "[102]\tvalidation_0-logloss:0.12057\n",
      "[103]\tvalidation_0-logloss:0.12061\n",
      "[104]\tvalidation_0-logloss:0.11995\n",
      "[105]\tvalidation_0-logloss:0.11941\n",
      "[106]\tvalidation_0-logloss:0.11921\n",
      "[107]\tvalidation_0-logloss:0.11914\n",
      "[108]\tvalidation_0-logloss:0.11912\n",
      "[109]\tvalidation_0-logloss:0.11896\n",
      "[110]\tvalidation_0-logloss:0.11886\n",
      "[111]\tvalidation_0-logloss:0.11842\n",
      "[112]\tvalidation_0-logloss:0.11823\n",
      "[113]\tvalidation_0-logloss:0.11816\n",
      "[114]\tvalidation_0-logloss:0.11822\n",
      "[115]\tvalidation_0-logloss:0.11815\n",
      "[116]\tvalidation_0-logloss:0.11820\n",
      "[117]\tvalidation_0-logloss:0.11821\n",
      "[118]\tvalidation_0-logloss:0.11796\n",
      "[119]\tvalidation_0-logloss:0.11775\n",
      "[120]\tvalidation_0-logloss:0.11760\n",
      "[121]\tvalidation_0-logloss:0.11750\n",
      "[122]\tvalidation_0-logloss:0.11750\n",
      "[123]\tvalidation_0-logloss:0.11735\n",
      "[124]\tvalidation_0-logloss:0.11729\n",
      "[125]\tvalidation_0-logloss:0.11688\n",
      "[126]\tvalidation_0-logloss:0.11702\n",
      "[127]\tvalidation_0-logloss:0.11728\n",
      "[128]\tvalidation_0-logloss:0.11716\n",
      "[129]\tvalidation_0-logloss:0.11633\n",
      "[130]\tvalidation_0-logloss:0.11612\n",
      "[131]\tvalidation_0-logloss:0.11610\n",
      "[132]\tvalidation_0-logloss:0.11589\n",
      "[133]\tvalidation_0-logloss:0.11559\n",
      "[134]\tvalidation_0-logloss:0.11540\n",
      "[135]\tvalidation_0-logloss:0.11534\n",
      "[136]\tvalidation_0-logloss:0.11509\n",
      "[137]\tvalidation_0-logloss:0.11508\n",
      "[138]\tvalidation_0-logloss:0.11483\n",
      "[139]\tvalidation_0-logloss:0.11495\n",
      "[140]\tvalidation_0-logloss:0.11487\n",
      "[141]\tvalidation_0-logloss:0.11471\n",
      "[142]\tvalidation_0-logloss:0.11468\n",
      "[143]\tvalidation_0-logloss:0.11448\n",
      "[144]\tvalidation_0-logloss:0.11462\n",
      "[145]\tvalidation_0-logloss:0.11450\n",
      "[146]\tvalidation_0-logloss:0.11414\n",
      "[147]\tvalidation_0-logloss:0.11389\n",
      "[148]\tvalidation_0-logloss:0.11367\n",
      "[149]\tvalidation_0-logloss:0.11359\n",
      "[150]\tvalidation_0-logloss:0.11350\n",
      "[151]\tvalidation_0-logloss:0.11351\n",
      "[152]\tvalidation_0-logloss:0.11336\n",
      "[153]\tvalidation_0-logloss:0.11307\n",
      "[154]\tvalidation_0-logloss:0.11303\n",
      "[155]\tvalidation_0-logloss:0.11302\n",
      "[156]\tvalidation_0-logloss:0.11282\n",
      "[157]\tvalidation_0-logloss:0.11234\n",
      "[158]\tvalidation_0-logloss:0.11225\n",
      "[159]\tvalidation_0-logloss:0.11216\n",
      "[160]\tvalidation_0-logloss:0.11208\n",
      "[161]\tvalidation_0-logloss:0.11184\n",
      "[162]\tvalidation_0-logloss:0.11179\n",
      "[163]\tvalidation_0-logloss:0.11183\n",
      "[164]\tvalidation_0-logloss:0.11133\n",
      "[165]\tvalidation_0-logloss:0.11121\n",
      "[166]\tvalidation_0-logloss:0.11116\n",
      "[167]\tvalidation_0-logloss:0.11111\n",
      "[168]\tvalidation_0-logloss:0.11104\n",
      "[169]\tvalidation_0-logloss:0.11080\n",
      "[170]\tvalidation_0-logloss:0.11075\n",
      "[171]\tvalidation_0-logloss:0.11067\n",
      "[172]\tvalidation_0-logloss:0.11049\n",
      "[173]\tvalidation_0-logloss:0.11053\n",
      "[174]\tvalidation_0-logloss:0.11048\n",
      "[175]\tvalidation_0-logloss:0.11035\n",
      "[176]\tvalidation_0-logloss:0.11038\n",
      "[177]\tvalidation_0-logloss:0.11041\n",
      "[178]\tvalidation_0-logloss:0.11049\n",
      "[179]\tvalidation_0-logloss:0.11055\n",
      "[180]\tvalidation_0-logloss:0.11055\n",
      "[181]\tvalidation_0-logloss:0.11048\n",
      "[182]\tvalidation_0-logloss:0.11041\n",
      "[183]\tvalidation_0-logloss:0.11034\n",
      "[184]\tvalidation_0-logloss:0.11036\n",
      "[185]\tvalidation_0-logloss:0.11028\n",
      "[186]\tvalidation_0-logloss:0.11039\n",
      "[187]\tvalidation_0-logloss:0.11059\n",
      "[188]\tvalidation_0-logloss:0.11051\n",
      "[189]\tvalidation_0-logloss:0.11054\n",
      "[190]\tvalidation_0-logloss:0.11056\n",
      "[191]\tvalidation_0-logloss:0.11072\n",
      "[192]\tvalidation_0-logloss:0.11064\n",
      "[193]\tvalidation_0-logloss:0.11038\n",
      "[194]\tvalidation_0-logloss:0.11012\n",
      "[195]\tvalidation_0-logloss:0.11014\n",
      "[196]\tvalidation_0-logloss:0.11010\n",
      "[197]\tvalidation_0-logloss:0.11004\n",
      "[198]\tvalidation_0-logloss:0.10992\n",
      "[199]\tvalidation_0-logloss:0.10990\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.1, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=-1, num_parallel_tree=6, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.1, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=-1, num_parallel_tree=6, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.1, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=-1, num_parallel_tree=6, ...)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, eval_set=[(X_cv, Y_cv)], early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888763904511936"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9585764294049008"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_cv, Y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9620991253644315"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[814  38]\n",
      " [ 27 836]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       852\n",
      "           1       0.96      0.97      0.96       863\n",
      "\n",
      "    accuracy                           0.96      1715\n",
      "   macro avg       0.96      0.96      0.96      1715\n",
      "weighted avg       0.96      0.96      0.96      1715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The model with the best accuracy in train and test is XGBClassifier</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Building a Pipeline with XGBClassifier for Deployment and Production</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
